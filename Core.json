{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1616567001789_-1158487978","id":"20210324-062321_419017666","dateCreated":"2021-03-24T06:23:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:21036","text":"sc","dateUpdated":"2021-03-24T06:23:27+0000","dateFinished":"2021-03-24T06:23:28+0000","dateStarted":"2021-03-24T06:23:27+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res39: org.apache.spark.SparkContext = org.apache.spark.SparkContext@1be20988\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1616567007577_1440875592","id":"20210324-062327_1280457643","dateCreated":"2021-03-24T06:23:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:21112","text":"sc.version","dateUpdated":"2021-03-24T06:26:08+0000","dateFinished":"2021-03-24T06:26:09+0000","dateStarted":"2021-03-24T06:26:08+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res40: String = 2.1.0\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1616567168928_1829885733","id":"20210324-062608_1651714677","dateCreated":"2021-03-24T06:26:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:21212","text":"val rdd = sc.parallelize(List(1,2,3,4,5,6,7,8,9), 2)","dateUpdated":"2021-03-24T06:35:11+0000","dateFinished":"2021-03-24T06:35:12+0000","dateStarted":"2021-03-24T06:35:11+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[78] at parallelize at <console>:27\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1616567711650_177167567","id":"20210324-063511_1460536601","dateCreated":"2021-03-24T06:35:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:21311","text":"rdd.first\nrdd.take(1)","dateUpdated":"2021-03-24T06:47:32+0000","dateFinished":"2021-03-24T06:47:33+0000","dateStarted":"2021-03-24T06:47:32+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res41: Int = 1\nres42: Array[Int] = Array(1)\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=30","http://172.17.0.2:4040/jobs/job?id=31"],"interpreterSettingId":"2CBEJNFR7"}}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1616568452734_-626315663","id":"20210324-064732_2024111529","dateCreated":"2021-03-24T06:47:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:21410","text":"rdd.collect\nrdd.collect.foreach(i => print(\"->\" + i))","dateUpdated":"2021-03-24T07:01:09+0000","dateFinished":"2021-03-24T07:01:11+0000","dateStarted":"2021-03-24T07:01:09+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res44: Array[Int] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9)\n->1->2->3->4->5->6->7->8->9"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=33","http://172.17.0.2:4040/jobs/job?id=34"],"interpreterSettingId":"2CBEJNFR7"}}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1616569181832_-842610481","id":"20210324-065941_517004249","dateCreated":"2021-03-24T06:59:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:21527","text":"rdd.mapPartitionsWithIndex((index: Int, iter: Iterator[Int]) => iter.toList.map(\"[partId:\" + index + \", val: \" +_+ \"]\").iterator).collect","dateUpdated":"2021-03-24T07:24:53+0000","dateFinished":"2021-03-24T07:24:54+0000","dateStarted":"2021-03-24T07:24:53+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res46: Array[String] = Array([partId:0, val: 1], [partId:0, val: 2], [partId:0, val: 3], [partId:0, val: 4], [partId:1, val: 5], [partId:1, val: 6], [partId:1, val: 7], [partId:1, val: 8], [partId:1, val: 9])\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=35"],"interpreterSettingId":"2CBEJNFR7"}}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1616570098745_-24302644","id":"20210324-071458_1360538834","dateCreated":"2021-03-24T07:14:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:21703","text":"%sh head /dataset/bank/bank.csv","dateUpdated":"2021-03-24T07:29:23+0000","dateFinished":"2021-03-24T07:29:23+0000","dateStarted":"2021-03-24T07:29:23+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\n30;\"unemployed\";\"married\";\"primary\";\"no\";1787;\"no\";\"no\";\"cellular\";19;\"oct\";79;1;-1;0;\"unknown\";\"no\"\n33;\"services\";\"married\";\"secondary\";\"no\";4789;\"yes\";\"yes\";\"cellular\";11;\"may\";220;1;339;4;\"failure\";\"no\"\n35;\"management\";\"single\";\"tertiary\";\"no\";1350;\"yes\";\"no\";\"cellular\";16;\"apr\";185;1;330;1;\"failure\";\"no\"\n30;\"management\";\"married\";\"tertiary\";\"no\";1476;\"yes\";\"yes\";\"unknown\";3;\"jun\";199;4;-1;0;\"unknown\";\"no\"\n59;\"blue-collar\";\"married\";\"secondary\";\"no\";0;\"yes\";\"no\";\"unknown\";5;\"may\";226;1;-1;0;\"unknown\";\"no\"\n35;\"management\";\"single\";\"tertiary\";\"no\";747;\"no\";\"no\";\"cellular\";23;\"feb\";141;2;176;3;\"failure\";\"no\"\n36;\"self-employed\";\"married\";\"tertiary\";\"no\";307;\"yes\";\"no\";\"cellular\";14;\"may\";341;1;330;2;\"other\";\"no\"\n39;\"technician\";\"married\";\"secondary\";\"no\";147;\"yes\";\"no\";\"cellular\";6;\"may\";151;2;-1;0;\"unknown\";\"no\"\n41;\"entrepreneur\";\"married\";\"tertiary\";\"no\";221;\"yes\";\"no\";\"unknown\";14;\"may\";57;2;-1;0;\"unknown\";\"no\"\n"}]}},{"text":"\nval bankText = sc.textFile(\"file:///dataset/bank/bank.csv\")\nbankText.cache","user":"anonymous","dateUpdated":"2021-03-24T07:38:17+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1616570963481_600943846","id":"20210324-072923_424305949","dateCreated":"2021-03-24T07:29:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:21881","dateFinished":"2021-03-24T07:38:18+0000","dateStarted":"2021-03-24T07:38:17+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"bankText: org.apache.spark.rdd.RDD[String] = file:///dataset/bank/bank.csv MapPartitionsRDD[83] at textFile at <console>:28\nres49: bankText.type = file:///dataset/bank/bank.csv MapPartitionsRDD[83] at textFile at <console>:28\n"}]}},{"text":"%spark bankText.count\nval bankhead = bankText.take(10)\nbankHead.size\n","user":"anonymous","dateUpdated":"2021-03-24T07:41:37+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1616571345917_427156647","id":"20210324-073545_106001056","dateCreated":"2021-03-24T07:35:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:21980","dateFinished":"2021-03-24T07:41:39+0000","dateStarted":"2021-03-24T07:41:37+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res52: Long = 4522\nbankhead: Array[String] = Array(\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\", 30;\"unemployed\";\"married\";\"primary\";\"no\";1787;\"no\";\"no\";\"cellular\";19;\"oct\";79;1;-1;0;\"unknown\";\"no\", 33;\"services\";\"married\";\"secondary\";\"no\";4789;\"yes\";\"yes\";\"cellular\";11;\"may\";220;1;339;4;\"failure\";\"no\", 35;\"management\";\"single\";\"tertiary\";\"no\";1350;\"yes\";\"no\";\"cellular\";16;\"apr\";185;1;330;1;\"failure\";\"no\", 30;\"management\";\"married\";\"tertiary\";\"no\";1476;\"yes\";\"yes\";\"unknown\";3;\"jun\";199;4;-1;0;\"unknown\";\"no\", 59;\"blue-collar\";\"married\";\"secondary\";\"no\";0;\"yes\";\"no\";\"unknown\";5;\"may\";226;1;-1;0;\"unknown\";\"no\", 35;\"management\";\"single\";\"tertiary\";\"no\";747;\"no\";\"no\";\"cellular\";23;\"feb\";141;2;176;3;\"failur...res53: Int = 10\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=38","http://172.17.0.2:4040/jobs/job?id=39"],"interpreterSettingId":"2CBEJNFR7"}}},{"text":"case class Bank(age: Integer, job: String, marital: String, education: String, balance: Integer)\nval bankRdd = bankText.map(_.split(\";\")).filter(_.head != \"\\\"age \\\"\").map(\n    s => Bank(s(0).toInt,\n    s(1).replaceAll(\"\\\"\", \"\"),\n    s(2).replaceAll(\"\\\"\", \"\"),\n    s(3).replaceAll(\"\\\"\", \"\"),\n    s(5).replaceAll(\"\\\"\", \"\").toInt\n    )\n    \n)\n","user":"anonymous","dateUpdated":"2021-03-24T07:49:37+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1616571564839_1521103395","id":"20210324-073924_903456754","dateCreated":"2021-03-24T07:39:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:22168","dateFinished":"2021-03-24T07:49:39+0000","dateStarted":"2021-03-24T07:49:37+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defined class Bank\nbankRdd: org.apache.spark.rdd.RDD[Bank] = MapPartitionsRDD[86] at map at <console>:31\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1616572116936_651749314","id":"20210324-074836_136588752","dateCreated":"2021-03-24T07:48:36+0000","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:22340","text":"bankRdd.saveAsTextFile(\"/tmp/bankRDD.txt\")","dateUpdated":"2021-03-24T07:50:56+0000","dateFinished":"2021-03-24T07:50:58+0000","dateStarted":"2021-03-24T07:50:56+0000","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 48.0 failed 1 times, most recent failure: Lost task 0.0 in stage 48.0 (TID 255, localhost, executor driver): java.lang.NumberFormatException: For input string: \"\"age\"\"\n\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n\tat java.lang.Integer.parseInt(Integer.java:569)\n\tat java.lang.Integer.parseInt(Integer.java:615)\n\tat scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)\n\tat scala.collection.immutable.StringOps.toInt(StringOps.scala:29)\n\tat $anonfun$3.apply(<console>:32)\n\tat $anonfun$3.apply(<console>:32)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:409)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply$mcV$sp(PairRDDFunctions.scala:1211)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply(PairRDDFunctions.scala:1210)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply(PairRDDFunctions.scala:1210)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1341)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1218)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1951)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1226)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1168)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1168)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1168)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1071)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1037)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1037)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1037)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:963)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:963)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:963)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:962)\n  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1488)\n  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1467)\n  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1467)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1467)\n  ... 47 elided\nCaused by: java.lang.NumberFormatException: For input string: \"\"age\"\"\n  at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n  at java.lang.Integer.parseInt(Integer.java:569)\n  at java.lang.Integer.parseInt(Integer.java:615)\n  at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)\n  at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)\n  at $anonfun$3.apply(<console>:32)\n  at $anonfun$3.apply(<console>:32)\n  at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)\n  at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply$mcV$sp(PairRDDFunctions.scala:1211)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply(PairRDDFunctions.scala:1210)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply(PairRDDFunctions.scala:1210)\n  at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1341)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1218)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)\n  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n  at org.apache.spark.scheduler.Task.run(Task.scala:99)\n  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)\n  ... 3 more\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=40"],"interpreterSettingId":"2CBEJNFR7"}}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1616572256707_957656982","id":"20210324-075056_275103134","dateCreated":"2021-03-24T07:50:56+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:22496"}],"name":"Core","id":"2G3H3WVWP","angularObjects":{"2CCMX5R9J:shared_process":[],"2CBEJNFR7:shared_process":[],"2CC4ZU7DE:shared_process":[],"2CA9YJVBZ:shared_process":[],"2CBRBCK1E:shared_process":[],"2CB345NPA:shared_process":[],"2CDPGFX2T:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}